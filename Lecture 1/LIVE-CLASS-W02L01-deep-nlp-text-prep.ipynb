{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69383602-32d0-44b4-86d5-a29d46674555",
   "metadata": {},
   "source": [
    "# AML Week 2, Lecture 1: Preparing Text for Deep NLP Models (TextVectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e37a1-8e2d-49f0-9652-39896926fd19",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc57c4f-3b2c-4f6f-86aa-68f474a45656",
   "metadata": {},
   "source": [
    "- How to create a train-test-val split for Tensorflow datasets from a train-test split. \n",
    "- How to use a Keras TextVectorization Layer\n",
    "- Demonstrate how tensorflow models using Sequences with Embedding Layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3487b0-db87-4f70-bc6c-a48e62956740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding parent directory to python path\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8d776-63e5-4a02-afd8-04628e4c858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the autoreload extension\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import demo  as fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fe76e-5fa7-436e-9634-d67e5b470eab",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b5806-1bf5-4c55-8e39-3f9159e26d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "with open(\"../Data-AmazonReviews/Amazon Product Reviews.md\") as f:\n",
    "    display(Markdown(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7e2ff-dcf2-4b44-addc-6215aa8a9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Then Set Random Seeds\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Then run the Enable Deterministic Operations Function\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# MacOS Sonoma Fix\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89879753-84c6-40cb-a2a8-8d6e7221cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "\n",
    "# Define a function for building an LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67cf1a-97b6-4d3b-b103-694e4a6c6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "df = joblib.load('../Data-AmazonReviews/processed_data.joblib')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88999b3f-1b93-49ee-950b-9f0bdb426be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups(x):\n",
    "    if x>=5.0:\n",
    "        return \"high\"\n",
    "    elif x <=2.0:\n",
    "        return \"low\"\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f5e92-f195-4ded-ac66-934ecb6644a2",
   "metadata": {},
   "source": [
    "To understand what customers do and do not like about Hoover products, we will define 2 groups:\n",
    "- High Ratings\n",
    "    - Overall rating = 5.0\n",
    "- Low Ratings\n",
    "    - Overall rating = 1.0 or 2.0\n",
    "\n",
    "\n",
    "We can use a function and .map to define group names based on the numeric overall ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda1d0b-e442-4f09-b334-c3397ab11834",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the function to create a new \"rating\" column with groups\n",
    "df['rating'] = df['overall'].map(create_groups)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ee180-c76f-4c0d-82fe-b156d001a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caeeaad-6db4-4dbf-a9e2-fcd3dfd30334",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check class balance of 'rating'\n",
    "df['rating'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9010c-9582-42e3-b958-507c65ad08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df_ml without null ratings\n",
    "df_ml = df.dropna(subset=['rating']).copy()\n",
    "df_ml.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd85e99-a07d-4475-9d20-134e1695c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X - Option A)  lemmas\n",
    "# def join_tokens(token_list):\n",
    "#     joined_tokens = ' '.join(token_list)\n",
    "#     return joined_tokens\n",
    "# X = df_ml['spacy_lemmas'].apply(join_tokens)\n",
    "\n",
    "# X - Option B) original raw text\n",
    "X = df_ml['text']\n",
    "\n",
    "# y - use our binary target \n",
    "y = df_ml['rating']\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea038ef0-08da-4dc5-b7b3-41f4652ca28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06184dc5-7b95-415d-ad4a-01b24f877d2a",
   "metadata": {},
   "source": [
    "# 📚 New For Today:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd218e-3911-49e7-9776-c07dc9087ae2",
   "metadata": {},
   "source": [
    "- Starting with a simple train-test-split for ML model (like in movie nlp project)\n",
    "- Resampling Imbalanced training data\n",
    "- Creating tensorflow dataset from X_train, y_train (so dataset is rebalanced)\n",
    "- Creating tensorflow dataset (intended to be split in 2 ) for X_test and y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486c413-1286-46df-b939-b6cc423e9b4e",
   "metadata": {},
   "source": [
    "## From Train-Test Split for ML to Train-Test-Val Split for ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c6b64-a923-4bcd-a899-8d1c43181cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 70:30 train test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "len(X_train_full), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5dc81c-53c6-486c-9beb-1ba5a86f6909",
   "metadata": {},
   "source": [
    "### Using Sklearn's LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f3486-8db8-4486-b931-bdc11d14a662",
   "metadata": {},
   "source": [
    "- Can't use text labels with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098d599-e5a0-4d07-b8aa-a61ae8659921",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4195576-f430-446b-853a-da86d2bf0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instansiate label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the training target\n",
    "y_train_full_enc = encoder.fit_transform(y_train_full)#.values)\n",
    "\n",
    "# Fit and tranform the test target\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "y_train_full_enc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8926d-f87c-40dd-b883-6ab44f054b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Class names saved as .classes_\n",
    "classes = encoder.classes_\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552b075-6d94-4ad7-8c05-025d60ac00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can inverse-transform \n",
    "encoder.inverse_transform([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7cb1dc-d13d-4dcb-80ca-b8301f0f3581",
   "metadata": {},
   "source": [
    "### Undersampling Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d98790-5804-4162-9e78-4b0b3ff8faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instantiate a RandomUnderSampler\n",
    "sampler = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d977d4-e6a1-4bf1-8b84-b50c216f0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train, y_train = sampler.fit_resample(X_train_full,y_train_full_enc)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69b21c-e59a-44f2-9619-ec706e571518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit_resample on the reshaped X_train data and y-train data\n",
    "X_train, y_train_enc = sampler.fit_resample(X_train_full.values.reshape(-1,1),\n",
    "                                        y_train_full_enc)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b6157b-9f31-48fb-80d0-db4c35f5fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reshaped X_train data back to 1D\n",
    "X_train = X_train.flatten()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898e60d-cb19-408e-91d4-e677f033a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class balance\n",
    "pd.Series(y_train_enc).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9880fe72-4a80-4135-ba02-1c2a5f873a21",
   "metadata": {},
   "source": [
    "## Previous Class' ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319c2f9-60a7-4f4e-b2e2-acf0a1fe0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b488903-2846-4bfc-a046-41ebb7ccebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create a model pipeline \n",
    "# count_pipe = Pipeline([('vectorizer',  CountVectorizer()), \n",
    "#                        ('naivebayes',  MultinomialNB())])\n",
    "\n",
    "# count_pipe.fit(X_train, y_train_enc)\n",
    "# fn.evaluate_classification(count_pipe, X_train, y_train_enc, X_test, y_test_enc,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80644-9fda-416e-80b6-789bb7a5903d",
   "metadata": {},
   "source": [
    "# Preparing For Deep NLP (Train-Test-Val Datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef132d-e442-485e-a634-acf94bf541ea",
   "metadata": {},
   "source": [
    "## 🕹️ Prepare Tensorflow Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da20ab9e-7e58-445b-a0bf-38f9926e8d56",
   "metadata": {},
   "source": [
    "Since we already have train/test X and y vars, we will make 2 dataset objects using tf.data.Dataset.from_tensor_slices.\n",
    "\n",
    "1. The training dataset using X_train, y_train (that we resampled/balanced)\n",
    "2. The val/test dataset using X_test, y-test.\n",
    "\n",
    "We will then split the val/test dataset into a val/test split.\n",
    "\n",
    "<!-- \n",
    "### T/T/V Split - Order of Operations (if using 1 dataset object)\n",
    "\n",
    "1) **Create full dataset object & Shuffle Once.**\n",
    "2) Calculate number of samples for training and validation data.\n",
    "3) Create the train/test/val splits using .take() and .skip()\n",
    "4) **Add shuffle to the train dataset only.**\n",
    "5) (Optional/Not Used on LP) If applying a transformation (e.g. train_ds.map(...)) to the data, add  here, before .cache()\n",
    "7) (Optional) Add .cache() to all splits to increase speed  (but may cause problems with large datasets)\n",
    "8) **Add .batch to all splits (default batch size=32)**\n",
    "9) (Optional) Add .prefetch(tf.data.AUTOTUNE)\n",
    "10) (Optional) Print out final length of datasets -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0658b2a-2c35-4f27-a06e-a54416aa9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data to Dataset Object\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train_enc))\n",
    "# Shuffle dataset once\n",
    "train_ds = train_ds.shuffle(len(train_ds), reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedeaafa-fa13-4309-a8a8-42913843b8c3",
   "metadata": {},
   "source": [
    "Create a test and validation dataset using X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e890160-24b8-4bcf-a3af-5d88bd0237a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test to dataset object to split\n",
    "val_test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69060a8-96f1-4398-9242-af1b3701b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate # of samples for 50/50 val/test split\n",
    "n_val_samples = int(len(val_test_ds) *.5)\n",
    "n_val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495b3b9-b89e-41c8-b597-d65a383cddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform the val/test split\n",
    "\n",
    "## Create the validation dataset using .take\n",
    "val_ds = val_test_ds.take(n_val_samples)\n",
    "\n",
    "## Create the test dataset using skip\n",
    "test_ds = val_test_ds.skip(n_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4a489-7074-49ea-be83-ea6c6f54cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the len gths of all 3 splits\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6305413-cb77-4238-9be5-f8ea32e7a9ee",
   "metadata": {},
   "source": [
    "### Adding Shuffling and Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afce4b-e39e-458b-b022-ac39ed9ca9ef",
   "metadata": {},
   "source": [
    "Let's examine a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4678d3f-baba-4962-87cf-00910be748f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a sample single element \n",
    "example_X, example_y= train_ds.take(1).get_single_element()\n",
    "print(example_X,'\\n\\n',example_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9ebe2-9d41-4641-8961-88c3dfa7adf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n",
    "example_X, example_y= train_ds.take(1).get_single_element()\n",
    "print(example_X,'\\n\\n',example_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27c52db3-92d2-4df6-822e-ee53198a20d8",
   "metadata": {},
   "source": [
    "Notice that we have the same example, the training data is not shuffling.\n",
    "\n",
    "Add .shuffle the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4969390-4e72-4e52-9fe7-41f83e683729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle only the training data every epoch\n",
    "train_ds = train_ds.shuffle(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8b84c-a4b2-464e-a7ef-21e2891df7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n",
    "example_X, example_y= train_ds.take(1).get_single_element()\n",
    "print(example_X,'\\n\\n',example_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8caedf-696c-4284-a224-194e64319af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n",
    "example_X, example_y= train_ds.take(1).get_single_element()\n",
    "print(example_X,'\\n\\n',example_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b99b4bd-6d3c-409e-956b-a7d2e0fd5916",
   "metadata": {},
   "source": [
    "> Add batching (use 32 for batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48eeddb-5554-4f37-a435-91ea27911e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setting the batch_size for all datasets\n",
    "BATCH_SIZE =32\n",
    "# use .batch to add batching to all 3 datasets\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "\n",
    "# Confirm the number of batches in each\n",
    "print (f' There are {len(train_ds)} training batches.')\n",
    "print (f' There are {len(val_ds)} validation batches.')\n",
    "print (f' There are {len(test_ds)} testing batches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498f8eb-bdaa-45bb-a809-f36014e03f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n",
    "example_X, example_y= train_ds.take(1).get_single_element()\n",
    "print(example_X,'\\n\\n',example_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48f3a6-6cb5-4065-9c49-4508e1f390c4",
   "metadata": {},
   "source": [
    "A single element now contains 32 samples since we set  batch_size to 32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a1990-85b6-4c25-852d-6049cae198a4",
   "metadata": {},
   "source": [
    "## 📚 Vectorizing Text with Keras's TextVectorization Layer (Demo)\n",
    "### Compare what is happening during text vectorization when using count versus sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b16927-1276-4d6d-a209-64fed6bcfec6",
   "metadata": {},
   "source": [
    "Flexible layer that can convert text to bag-of-words or sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb84974-50fe-466f-81d6-9e6a6f5a22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for demo \n",
    "example_text = ['Sometimes I love this vacuum, sometimes i hate this vacuum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d149c9a-8735-465b-b48a-ca8ba82dcee9",
   "metadata": {},
   "source": [
    "### TextVectorization Layer - Demo Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396378c7-cdc7-45d7-bacd-967abdf5f581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create text Vectorization layer - set to count vectorization\n",
    "count_vectorizer = tf.keras.layers.TextVectorization(output_mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c1dde-7d3a-4f62-ba2f-09fb5fd17194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocabulary from the vectorization layer.\n",
    "count_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5f1c8-8f2f-47d9-a9e2-5bc9d232c247",
   "metadata": {},
   "source": [
    "- Before training, only contains the out of vocab token ([UNK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93a1b0-e470-4e79-8c91-9f3d58d5e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the vectorizer using .adapt\n",
    "count_vectorizer.adapt(example_text)\n",
    "# Check the vocabulary after training the layer.\n",
    "count_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666ae7b-f4cc-43f8-ba87-294e7a99b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert example to count-vectorization\n",
    "counts = count_vectorizer(example_text)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2b3aa-03fb-4a4e-a9a4-2f4ab05acb7f",
   "metadata": {},
   "source": [
    "- Size of vectorized text - column for every word in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37577f-0738-4836-89bd-392d3b4ffc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the counts as as DataFrame \n",
    "pd.DataFrame(counts.numpy(), columns=count_vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec6f78-c06a-4299-95d1-6445ba7c8fd3",
   "metadata": {},
   "source": [
    "### TextVectorization Layer - Demo Sequence Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376e380-0416-491a-a68a-417de91c3689",
   "metadata": {},
   "source": [
    "- Output_mode='int' returns sequences.\n",
    "- Length is set by data scientist, use 20 for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2aeb45-d8d4-4c6f-a11d-914b1a5f8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text Vectorization layer for sequences\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(output_mode='int',output_sequence_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3381ee3-2a32-412d-bab6-61bf02edaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the vocabulary of the new sequence vectorizer.\n",
    "vocab =  sequence_vectorizer.get_vocabulary()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75655a0f-7d0b-4cf8-bc7a-3a9063662904",
   "metadata": {},
   "source": [
    "- Before training, only contains the out of vocab token ([UNK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711794b0-ee24-4917-996f-33c59ef1b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer using .adapt\n",
    "sequence_vectorizer.adapt(example_text)\n",
    "# Check the vocabulary after training the layer\n",
    "vocab =  sequence_vectorizer.get_vocabulary()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f19ae-86f6-4617-85fd-a68d8934a011",
   "metadata": {},
   "source": [
    "To demonstrate how sequences are used, we will make a dictionary with the integer code as the key and the corresponding word as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d128654-ce00-4827-bd86-90737a54e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionaries to look up words from ints \n",
    "int_to_str  = {idx:word for idx, word in enumerate(vocab)} # Dictionary Comprehension\n",
    "int_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffffb57-fbe8-4c2f-9ad0-a1e138733fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert example to sequences\n",
    "sequences = sequence_vectorizer(example_text)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a752e-9554-432e-8f0d-d3f0612a6d80",
   "metadata": {},
   "source": [
    "- Why are there 0s at the end of the sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da990d10-2a75-4e0b-804e-a302b4f02bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot be made into a dataframe\n",
    "try:\n",
    "    pd.DataFrame(sequences, columns = vocab)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04958dbd-126d-41a4-b63e-9a4e0e420d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sequences as numpy array for the loop below\n",
    "sequences = sequences.numpy()\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdad54-2f2b-42dc-ab07-5be556033ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each integer code, display the corresponding word\n",
    "for val in sequences[0]:\n",
    "    print(f\"{val} = {int_to_str[val]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a574b868-c730-4524-b129-c85f6ceb36ca",
   "metadata": {},
   "source": [
    "##  Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cfa99-1ce6-4dbd-b02f-b331a1aa6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Size of the Vocab\n",
    "VOCAB_SIZE = sequence_vectorizer.vocabulary_size()\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed794019-1e9e-491a-8133-f9046d69de41",
   "metadata": {},
   "source": [
    "The embedding layer needs the number of words in the input (input_dim), and the desired embedding dimensions. (e.g. 100,200,300).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c208b-4130-4ce3-a4fc-a2ff082acd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding layer of desired # of values\n",
    "EMBED_DIM = 50\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                           output_dim=EMBED_DIM,\n",
    "                                           input_length= 20)\n",
    "embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e72fb-85c0-4886-8958-48785c41a0fc",
   "metadata": {},
   "source": [
    "### Demonstrating Sequence to Vector Embedding Lookup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e4b47-9546-4171-8c73-9965bed7b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Model Needed to Create Embedding Layer for Vocab\n",
    "demo_embed = Sequential()\n",
    "demo_embed.add(sequence_vectorizer)\n",
    "demo_embed.add(embedding_layer)\n",
    "demo_embed.compile(optimizer='adam', loss='mse')\n",
    "demo_embed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304d1d9-f7ce-4c77-bded-5cd634bb9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding has row per word with EMBED_DIM of 50\n",
    "sequence_vectorizer.vocabulary_size(), EMBED_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1031169-4d97-43d2-aa3d-1679b93fb34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights from the embedding layer (this is your actual embedding matrix)\n",
    "embedding_weights = demo_embed.layers[1].get_weights()[0]\n",
    "embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e38ae-2376-4fb2-9cac-dc92a50f4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview one set of embedding weights\n",
    "embedding_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c73d1-12c4-4c64-b751-b706fd5925db",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d688fe-4d0f-4861-a217-adb9674bf48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show embeddings for each token in the sequence\n",
    "for val in sequences[0]:\n",
    "    print(f\"{val} = {int_to_str[val]}\")\n",
    "    print(embedding_weights[val])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8a3b0-38dd-4b2e-aa58-2fcfbca5de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b135ac0-2f86-43e6-b453-bcb23e580185",
   "metadata": {},
   "source": [
    "# LECTURE 1 STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5be88e-f906-4d45-a48e-aea90d1017df",
   "metadata": {},
   "source": [
    "### Word Vectors Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc825c1d-f1b2-427e-8ed3-4fe627b2bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the words and their corresponding vectors\n",
    "vector_dict = {}\n",
    "for i, word in int_to_str.items():#tokenizer.word_index.items():\n",
    "    # Save the weights for word (based on numeric index)\n",
    "    vector_dict[word]= embedding_weights[i] \n",
    "\n",
    "    # vector_list.append(embedding_weights[i])\n",
    "vector_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804c401-996b-4386-8db4-dd585d5c56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the vector for \"love\"\n",
    "vector_dict['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a9432-9aa5-4d33-9b3b-5dbe432773e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the vector for \"hate\"\n",
    "vector_dict['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d419d9f-38e3-4f75-96ac-4a9cdc63cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors can be added/subtracted to get output vector - then find most similar word  \n",
    "vector_dict['hate'] + vector_dict['love'] + vector_dict['vacuum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab650c-081c-44c6-afa4-33c234192bd7",
   "metadata": {},
   "source": [
    "## Word Embeddings Demo (Pre-Trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12b1c6-ea27-41ab-bc5d-a00c296d9d4b",
   "metadata": {},
   "source": [
    "###  Pretrianed Word Embeddings with GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247fc46-ace7-4a56-9fcd-d6236028aef6",
   "metadata": {},
   "source": [
    "- [Click here](https://nlp.stanford.edu/data/glove.6B.zip) to start donwnloading GloVe zip file (glove.6B.zip)\n",
    "- Unzip the downloaded zip archive.\n",
    "- Open the extracted folder and find the the `glove.6B.100d.txt` file. (Size is over 300MB )\n",
    "- Move the text file from Downloads to the same folder as this notebook.\n",
    "- **Make sure to ignore the large file using GitHub Desktop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d787ab9-41a7-4c09-bd99-76722f369f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load GloVe vectors into a gensim model\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"glove.6B.100d.txt\", binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859c359-c117-4d4c-b745-a5c0591c8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now use `glove_model` to access individual word vectors, similar to a dictionary\n",
    "vector = glove_model['king']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cfa48-3101-4f11-b95f-86a2da36dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16f619-2d0b-4443-869a-801a3fb40313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similarity between words\n",
    "glove_model.similarity('king', 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0366fee-7698-44a3-b281-1d55518ec2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform word math\n",
    "result = glove_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6bd42-f0a0-4ad0-a301-5790f22b24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use glove to calculate the most similar\n",
    "glove_model.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631163a-290a-4086-8525-2ead60ae42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['king'] - glove_model['man'] + glove_model['woman']\n",
    "new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62f9b9-696b-4186-baa0-96306023a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .most_similar with an array\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446cc69-1265-4e2e-a777-875ee070fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['monarchy'] + glove_model['vote'] + glove_model['government']\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf957d-31af-4be4-aeeb-dc909a6a2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['baby'] + glove_model['age']\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede594e-cd14-4cdd-85ad-19065d899744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['baby'] + glove_model['baby']\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f05532-5113-4208-9163-c933b816d7e1",
   "metadata": {},
   "source": [
    "# Returning to Hoover Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401b00d-d9b2-416c-b171-2e3cace3dd92",
   "metadata": {},
   "source": [
    "### Create the Training Texts Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5cc8b-963d-4a78-a33f-4f134509e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the layer on the training texts\n",
    "try:\n",
    "    sequence_vectorizer.adapt(train_ds)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45da873-5e7a-4e92-b4ca-939ad5c0e1f2",
   "metadata": {},
   "source": [
    "> We need to get a version of our data that is **only the texts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a346be-2bf5-483d-8c13-4074fb506730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the text_ds from ds_train\n",
    "\n",
    "# Preview the text_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ad04a-c1c2-4c5e-bfa7-f7ce64e7a536",
   "metadata": {},
   "source": [
    "### Determine appropriate sequence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fbbd2-718b-4766-912a-9fef9aa862ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ml['length (characters)'] = df_ml['text'].map(len)\n",
    "# df_ml.head(3)\n",
    "\n",
    "# ax = sns.histplot(data=df_ml, hue='rating', x='length (characters)',\n",
    "#                 stat='percent',common_norm=False)#, estimator='median',);\n",
    "# ax.axvline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9713fe-43cb-4bb9-aebc-e31601c543db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the length of the each text\n",
    "# We will split on each space, and then get the length\n",
    "df_ml['length (tokens)'] = df_ml['text'].map( lambda x: len(x.split(\" \")))\n",
    "df_ml['length (tokens)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473f73c-0ac0-461e-a186-bf45ad560e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 150\n",
    "ax = sns.histplot(data=df_ml, hue='rating', x='length (tokens)',kde=True,\n",
    "                stat='probability',common_norm=False)#, estimator='median',);\n",
    "ax.axvline(SEQUENCE_LENGTH, color='red', ls=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6aed55-e62e-4375-8d80-17223bcdb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # Define a function to calculate cosine similarity\n",
    "# def find_closest_embeddings(embedding):\n",
    "    \n",
    "#     return sorted(vector_dict.keys(), key=lambda word: cosine_similarity([vector_dict[word]], [embedding]))\n",
    "\n",
    "# # Example of finding words similar to 'vacuum' \n",
    "# similar_to_vacuum = find_closest_embeddings(vector_dict['vacuum'])[:5]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words\n",
    "# print(\"Words similar to 'vacuum':\", similar_to_vacuum)\n",
    "\n",
    "# # Demonstration of vector arithmetic: 'hate' + 'love' + 'vacuum'\n",
    "# combined_vector = vector_dict['hate'] + vector_dict['love'] + vector_dict['vacuum']\n",
    "# similar_to_combined = find_closest_embeddings(combined_vector)[:5]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words to the combined vector\n",
    "# print(\"Words similar to the combination of 'hate', 'love', and 'vacuum':\", similar_to_combined)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628c644-cf83-4cd6-abe8-c181c3af2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example of finding words similar to 'vacuum' \n",
    "# n_results = 5\n",
    "# demo_word = 'vacuum'\n",
    "# add_word = 'love'\n",
    "\n",
    "# similar_to_vacuum = find_closest_embeddings(vector_dict[demo_word])[:n_results]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words\n",
    "# print(f\"Words similar to '{demo_word}':\")\n",
    "# print(similar_to_vacuum)\n",
    "\n",
    "# # Demonstration of vector arithmetic: 'hate' + 'love' + 'vacuum'\n",
    "# combined_vector =vector_dict[add_word] + vector_dict[demo_word]# vector_dict['hate'] + \n",
    "\n",
    "# similar_to_combined = find_closest_embeddings(combined_vector)[:n_results]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words to the combined vector\n",
    "# print(f\"\\nWords similar to the combination of {demo_word} + {add_word}\")\n",
    "# print(similar_to_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1a448-8cc1-4bac-8896-0d278ebcfc5f",
   "metadata": {},
   "source": [
    "# Our First Deep Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530ad65-1a61-43b7-bbfa-0b9c9c42c6d1",
   "metadata": {},
   "source": [
    "### Combining the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95210b15-3546-48cb-9e2e-85669af45e6d",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46088607-41ee-49b1-93a4-d2405e591730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create text Vectorization layer\n",
    "SEQUENCE_LENGTH = None\n",
    "EMBED_DIM = None\n",
    "\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "sequence_vectorizer.adapt(ds_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873c9d2-f3f2-4b75-9230-c4caef9ebb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = sequence_vectorizer.vocabulary_size()\n",
    "\n",
    "\n",
    "# Define sequential model with pre-trained vectorization layer and *new* embedding layer\n",
    "model = Sequential([\n",
    "    sequence_vectorizer,\n",
    "    layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                              output_dim=EMBED_DIM, \n",
    "                              input_length=SEQUENCE_LENGTH)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721207e-992b-449f-8892-f053704a70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model(text_vectorization_layer):\n",
    "    VOCAB_SIZE = text_vectorization_layer.vocabulary_size()\n",
    "    SEQUENCE_LENGTH = sequence_vectorizer.get_config()['output_sequence_length']\n",
    "    \n",
    "    \n",
    "    # Define sequential model with pre-trained vectorization layer and *new* embedding layer\n",
    "    model = Sequential([\n",
    "        text_vectorization_layer,\n",
    "        layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                  output_dim=EMBED_DIM, \n",
    "                                  input_length=SEQUENCE_LENGTH)\n",
    "        ])\n",
    "        \n",
    "    # Add *new* LSTM layer\n",
    "    model.add(layers.SimpleRNN(32)) #BEST=32\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    " \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizers.legacy.Adam(learning_rate = .001), \n",
    "                  loss='bce',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
    "    return [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5658e-544d-44ab-911a-4ded171ac3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the lstm model and specify the vectorizer\n",
    "rnn_model = build_rnn_model(sequence_vectorizer)\n",
    "\n",
    "# Defien number of epocs\n",
    "EPOCHS = 30\n",
    "# Fit the model\n",
    "history = rnn_model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(patience=5),\n",
    ")\n",
    "fn.plot_history(history,figsize=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74a307-abc8-4713-bc8f-44ca51062faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the results\n",
    "results = fn.evaluate_classification_network(\n",
    "    rnn_model, X_train=train_ds, \n",
    "    X_test=test_ds,# history=history\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273488b-df60-476b-9c46-8e376679e835",
   "metadata": {},
   "source": [
    "# Next Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd497e6f-a936-46c8-a175-920a5d729f98",
   "metadata": {},
   "source": [
    "> We will continue with this task and introduce and apply various sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543406c-f744-4ff0-9625-041f01863b59",
   "metadata": {},
   "source": [
    "# APPENDIX - Save for Next Lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be57a84-b485-42c6-b580-f46ac5bd835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEMP/EXP - extract embedding matrix\n",
    "\n",
    "embedding_weights = rnn_model.layers[1].get_weights()[0]\n",
    "embedding_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5507d21-5512-4835-b99c-d9c6cdac338c",
   "metadata": {},
   "source": [
    "> - Conceptual example of using the maximum value as final result.\n",
    "> - Relate to GlovalMaxPooling1D() layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bffeeb-9b97-4fb0-a428-f7daefbdde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the MAX values (relate to GlobalMaxPooling)\n",
    "max_vector = np.max((vector_dict['hate'], vector_dict['love'] ,vector_dict['vacuum']), axis=0)\n",
    "print(max_vector.shape)\n",
    "max_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d43288-b4bb-4145-a6ad-cb7efe7b5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Average values (relate to GlobalMaxPooling)\n",
    "avg_vector = np.mean((vector_dict['hate'], vector_dict['love'] ,vector_dict['vacuum']), axis=0)\n",
    "print(avg_vector.shape)\n",
    "avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d4c28-6334-4cfd-aa18-b05044c321e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
